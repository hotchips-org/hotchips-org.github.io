---
comments: false
date: 2018-05-30 05:56:49+00:00
layout: page
link: http://www.hotchips.org/archives/2010s/hc30/
slug: hc30
title: HC30 (2018)
wordpress_id: 3697
---
Held at The Flint Center for the Performing Arts, Cupertino, California, Sunday-Tuesday, August 19-21, 2018.

# All Proceedings

* [Zipfile of All HC30 files (161MB)](/hc30/4allslides/hc30_all_slides_v20180821_4.zip)

# Videos

* Tutorial 1: [Blockchains and Distributed Ledgers](https://youtu.be/BIKKp6cfqWI)
* Tutorial 2: [Architectures for Accelerating Deep Neural Nets](https://youtu.be/ydsZ7A0FF0I)
* Session 1: [Mobile/Power efficient processors](https://youtu.be/_mZORF2vHAA)
* Session 2: [Graphics Solutions](https://youtu.be/k7EGUb6xn-Q)
* Keynote 1: [Spectre/Meltdown and What It Means for Future Chip Design](https://youtu.be/d5XzVF0sAZo)
* Session 3: [IoT/Edge Computing](https://youtu.be/fNQQWvB3PfM)
* Session 4: [Security](https://youtu.be/ve_64dbM4YI)
* Session 5: [Switching Fabrics and FPGA Architectures](https://youtu.be/CtD4KMyNbAA)
* Session 6: [New Technologies](https://youtu.be/Uh6y825V8M8)
* Keynote 2: [Adaptable Intelligence: the Next Computing Era](https://youtu.be/xnNs74tTHZU)
* Session 7: [Machine Learning I](https://youtu.be/lQ1wUnsh5Qk)
* Session 8: [Machine Learning II](https://youtu.be/zbtZ-rALqF4)
* Session 9: [Server Processors](https://youtu.be/6GQaKkcaPek)

# At a Glance

* Sunday 8/19: Tutorials
  * 8:00 AM - 9:15 AM: Breakfast
  * 9:15 AM - 12:45 PM: Tutorial 1: Blockchains and Distributed Ledgers (Chair: Geoffrey Burr)
  * 12:45 PM - 2:00 PM: Lunch
  * 2:00 PM - 5:00 PM: Tutorial 2: Architectures for Accelerating Deep Neural  Nets (Chair: Kurt Keutzer)
  * 5:00 PM - 6:00 PM: Reception
* Monday 8/20: Conference Day 1
  * 7:30 AM - 9:15 AM: Breakfast
  * 9:15 AM - 9:30 AM: Opening Remarks
  * 9:30 AM - 11:00 AM: Mobile/Power efficient processors (Chair: Alisa Scherer)
  * 11:00 AM - 11:30 AM: Break
  * 11:30 AM - 12:30 PM: Graphics Solutions (Chair: Ralph Wittig)
  * 12:30 PM - 1:45 PM: Lunch
  * 1:45 PM - 3:30 PM: Keynote: Spectre/Meltdown and What It Means for Future Chip Design (Chair: Partha Ranganathan)
  * 3:30 PM - 4:00 PM: Break
  * 4:00 PM - 5:30 PM: IoT/Edge Computing (Chair: Bill Dally)
  * 5:30 PM - 6:30 PM: Security (Chair: Alan Smith)
  * 6:30 PM - 7:30 PM: Reception (Wine & Snacks)
* Tuesday 8/21: Conference Day 2
  * 7:45 AM - 8:45 AM: Breakfast
  * 8:45 AM - 10:15 AM: Switching Fabrics and FPGA Architectures (Chair: Pradeep Dubey)
  * 10:15 AM - 10:45 AM: Break
  * 10:45 AM - 11:45 AM: New Technologies (Chair: Forest Baskett)
  * 11:45 AM - 12:45 PM: Keynote 2: Adaptable Intelligence: the Next Computing Era (Chair:John Hennessy)
  * 12:45 PM - 2:00 PM: Lunch
  * 2:00 PM - 3:30 PM: Machine Learning I (Chair: Gary Lauterbach)
  * 3:30 PM - 4:30 PM: Machine Learning II (Chair: Ian Bratt)
  * 4:30 PM - 5:00 PM: Break
  * 5:00 PM - 7:00 PM: Server Processors (Chair: Dileep Bhandarkar)
  * 7:00 PM - 7:15 PM: Closing Remarks

# Tutorials


<table > 
<tbody >
<tr >

<td >**Sun 8/19**
</td>

<td >**Tutorial**
</td>

<td >**Title**
</td>

<td >**Presenter**
</td>

<td >**Affiliation**
</td>
</tr>
<tr >

<td style="width: 64px;" >8:00 AM
</td>

<td style="width: 91px;" >Breakfast
</td>

<td style="width: 204px;" >
</td>

<td style="width: 123px;" >
</td>

<td style="width: 102px;" >
</td>
</tr>
<tr >

<td style="width: 64px;" >9:15 AM
</td>

<td style="width: 91px;" >T1
</td>

<td style="width: 204px;" >[A New Era in Distributed Computing with Blockchains and Databases](/hc30/0tutorials/T1_Part_1_A_New_Era_in_Distributed_Computing.pdf)
</td>

<td colspan="2" style="width: 225px;" >**_Dr. C. Mohan_**_, IBM Fellow, IBM Research–Almaden_
</td>
</tr>
<tr >

<td colspan="5" style="width: 584px;" >**_Abstract:_**__

A new era is emerging in the world of distributed computing with the growing popularity of blockchains (shared, replicated and distributed ledgers) and the associated databases as a way of integrating inter-organizational work. Originally, the concept of a distributed ledger was invented as the underlying technology of the cryptocurrency Bitcoin. But the adoption and further adaptation of it for use in the commercial or permissioned environments is what is of utmost interest to me and hence will be the focus of this tutorial. Computer companies like IBM and Microsoft, and many key players in different vertical industry segments have recognized the applicability of blockchains in environments other than cryptocurrencies. IBM did some pioneering work by architecting and implementing Fabric, and then open sourcing it. Now Fabric is being enhanced via the Hyperledger Consortium as part of The Linux Foundation. A few of the other efforts include Enterprise Ethereum, R3 Corda and BigchainDB.

While there is no standard in the blockchain space currently, all the ongoing efforts involve some combination of database, transaction, encryption, consensus and other distributed systems technologies. Some of the application areas in which blockchain pilots are being carried out are: smart contracts, supply chain management, know your customer, derivatives processing and provenance management. In this talk, I will survey some of the ongoing blockchain projects with respect to their architectures in general and their approaches to some specific technical areas. I will focus on how the functionality of traditional and modern data stores are being utilized or not utilized in the different blockchain projects. I will also distinguish how traditional distributed database management systems have handled replication and how blockchain systems do it. Since most of the blockchain efforts are still in a nascent state, the time is right for database and other distributed systems researchers and practitioners to get more deeply involved to focus on the numerous open problems.
</td>
</tr>
<tr >

<td >11:15 AM
</td>

<td >Break
</td>

<td >
</td>

<td >
</td>

<td >
</td>
</tr>
<tr >

<td >11:45 AM
</td>

<td >T1
</td>

<td >Introduction to XRP and the XRP Ledger
</td>

<td colspan="2" >Yana Novikova, Senior Product Manager, Ripple
</td>
</tr>
<tr >

<td colspan="5" style="width: 584px;" >**Abstract:**

The XRP Ledger is a decentralized cryptographic ledger powered by a network of peer-to-peer servers. The XRP Ledger is the home of XRP, a decentralized digital asset built for payments and a source of liquidity that bridges different currencies worldwide.

What sets the XRP Ledger apart is its unique consensus algorithm that does not require the time and energy of "mining," the way other such systems do. Instead of "proof of work" or even "proof of stake," the XRP Ledger's consensus algorithm uses a system where every participant has an overlapping set of "trusted validators" and those trusted validators efficiently agree on which transactions happen in what order. As of early 2018, the Bitcoin network uses more electricity per transaction than a US family home uses in an entire day, and confirming the transaction takes hours. In comparison, a single XRP transaction uses a negligible amount of electricity, and takes less than 4 or 5 seconds to confirm.

Abstractly, the XRP Ledger is a replicated state machine. The replicated state is the ledger maintained by each node in the network (both validator and tracking) and state transitions correspond to transactions submitted by clients of the network. Once validator nodes agree on sets of transactions to apply to the state, the XRP Ledger protocol specifies deterministic rules for ordering transactions within each set and how to apply transactions to generate the new ledger state. Thus, the role of the XRP Ledger Consensus Protocol (LCP) is only to make the network reach agreement on sets of transactions even in the presence of faulty or malicious participants (Byzantine), guaranteeing that every node generates a consistent ledger.

While several consensus algorithms exist for the Byzantine Generals Problem, specifically as it pertains to distributed payment systems, many suffer from high latency induced by the requirement that all nodes within the network communicate synchronously. XRP Ledger consensus algorithm that circumvents this requirement by utilizing collectively-trusted subnetworks within the larger network, where the “trust” required of these subnetworks is in fact minimal and can be further reduced with principled choice of the member nodes. In addition minimal connectivity is required to maintain agreement throughout the whole network. The result is a low-latency consensus algorithm which still maintains robustness in the face of Byzantine failures.
</td>
</tr>
<tr >

<td style="width: 64px;" >12:45 PM
</td>

<td style="width: 91px;" >Lunch
</td>

<td style="width: 204px;" >
</td>

<td style="width: 123px;" >
</td>

<td style="width: 102px;" >
</td>
</tr>
<tr >

<td >2:00 PM
</td>

<td >T2
</td>

<td colspan="3" >Architectures for Accelerating Deep Neural Nets
</td>
</tr>
<tr >

<td colspan="5" style="width: 584px;" >**Abstract:**
In the first portion of this tutorial, we provide a very brief introduction to Deep Neural Nets and their applications in computer vision, speech recognition, and other areas. We review the two key computational elements of Deep Neural Nets: inference and training in regards to their compute and memory requirements. Finally, we review popular target architectures for supporting these applications, including CPUs, GPUs, and custom DNN accelerators, including a discussion around common micro-architectures for acceleration of typical computational patterns and computational considerations around batch sizes, quantization and pruning.In the second portion of this tutorial we turn our focus to the problem of accelerating inference in edge devices. The devices range from autonomous vehicles, through mobile phones to very low power IOT devices. We consider both the real-time speed requirements of these applications as well as power and energy constraints. We consider effective design principles for reducing the computational requirements of DNNs and useful techniques for quantization/compression of DNN computations. We then go into depth on accelerator architectures for meeting these constraints.In the last portion of this tutorial we consider the problem of training Deep Neural Nets, particularly in the cloud. We briefly examine the ubiquitous synchronous stochastic gradient descent and asynchronous variants. We look at the problem of scaling DNN training on distributed multiprocessors and its attendant problems of increasing batch size and balancing computation and communication. We then broadly survey the architectures to support training, including special purpose accelerators.
</td>
</tr>
<tr >

<td style="width: 64px;" >2:00 PM
</td>

<td style="width: 91px;" >T2
</td>

<td style="width: 204px;" >[Overview of Deep Learning and Computer Architectures for Accelerating DNNs](/hc30/0tutorials/T2_Part_1_Overview_finalv3.pdf)
</td>

<td style="width: 123px;" >Michaela Blott
</td>

<td style="width: 102px;" >Xilinx Research
</td>
</tr>
<tr >

<td style="width: 64px;" >2:50 PM
</td>

<td style="width: 91px;" >T2
</td>

<td style="width: 204px;" >[Accelerating Inference at the Edge](/hc30/0tutorials/T2_Part_2_Song_Hanv3.pdf)
</td>

<td style="width: 123px;" >Song Han
</td>

<td style="width: 102px;" >Assistant Professor, MIT
</td>
</tr>
<tr >

<td style="width: 64px;" >3:40 PM
</td>

<td style="width: 91px;" >Break
</td>

<td style="width: 204px;" >
</td>

<td style="width: 123px;" >
</td>

<td style="width: 102px;" >
</td>
</tr>
<tr >

<td style="width: 64px;" >4:10 PM
</td>

<td style="width: 91px;" >T2
</td>

<td style="width: 204px;" >[Accelerating Training in the Cloud](/hc30/0tutorials/T2_Part_3_HotChips30TrainingTutorial.pdf)
</td>

<td style="width: 123px;" >William L. Lynch, Ardavan Pedram
</td>

<td style="width: 102px;" >Cerebras Systems
</td>
</tr>
<tr >

<td style="width: 64px;" >5:00 PM
</td>

<td style="width: 91px;" >Reception
</td>

<td style="width: 204px;" >
</td>

<td style="width: 123px;" >
</td>

<td style="width: 102px;" >
</td>
</tr>
<tr >

<td style="width: 64px;" >6:00 PM
</td>

<td style="width: 91px;" >End of Reception
</td>

<td style="width: 204px;" >
</td>

<td style="width: 123px;" >
</td>

<td style="width: 102px;" >
</td>
</tr>
</tbody>
</table>

<table > 
<tbody >
<tr >

<td >Mon 1:45 PM
</td>

<td >Keynote 1: Spectre/Meltdown
</td>

<td >[The era of security: Introduction](/hc30/1conf/1.07_Hotchips_Security_Keynote.pdf)
</td>

<td >John Hennessy
</td>

<td >Stanford/Google
</td>
</tr>
<tr >

<td >Tue 11:45 AM
</td>

<td >Keynote 2
</td>

<td >[Adaptable Intelligence: the Next Computing Era](/hc30/2conf/2.06_Victor_Hot_Chips_8_21_2018_Keynote_FINAL.pdf)
</td>

<td >Victor Peng
</td>

<td >CEO, Xilinx
</td>
</tr>
</tbody>
</table>

# Conference Day1

<table style="height: 1045px;" > 
<tbody >
<tr >

<td >**Mon 8/20**
</td>

<td >**Session**
</td>

<td >**Title**
</td>

<td >**Presenter**
</td>

<td >**Affiliation**
</td>
</tr>
<tr style="height: 48px;" >

<td >7:30 AM
</td>

<td >Breakfast
</td>

<td >
</td>

<td >
</td>

<td >
</td>
</tr>
<tr style="height: 48px;" >

<td >9:15 AM
</td>

<td >Intro
</td>

<td >Opening Remarks by Conference Chairs[ Part A ](/hc30/1conf/1.00a_HC30_Welcome_v3.pdf)[ Part B ](/hc30/1conf/1.00b_HC30_Welcome_TPC.pdf)
</td>

<td colspan="2" >David Lau (MIPS), John Kubiatowicz (UC Berkeley), Stefan Rusu (TSMC)
</td>
</tr>
<tr style="height: 73px;" >

<td >9:30 AM
</td>

<td >Mobile/Pwr Efficient Processors
</td>

<td >[Samsung's Exynos-M3 CPU](/hc30/1conf/1.01_Samsung_Exynos_HotChips_MK_rev2.pdf)
</td>

<td >Jeff Rupley
</td>

<td >Samsung Electronics
</td>
</tr>
<tr style="height: 210px;" >

<td >10:00 AM
</td>

<td >
</td>

<td >[The Pixel Visual Core: Google's Fully Programmable Image, Vision and AI Processor for Mobile Devices](/hc30/1conf/1.02_Google_HC30.Google.JasonRedgrave.V01.pdf)
</td>

<td >Jason Redgrave, Albert Meixner, Nathan Goulding-Hotta, Artem Vasilyev and Ofer Shacham
</td>

<td >Google
</td>
</tr>
<tr style="height: 185px;" >

<td >10:30 AM
</td>

<td >
</td>

<td >[BROOM: An open-source Out-of-Order processor with resilient low-voltage operation in 28nm CMOS](/hc30/1conf/1.03_Berkeley_BROOM_HC30.Berkeley.Celio.v02.pdf)
</td>

<td >Christopher Celio, Pi-Feng Chiu, Krste Asanovic, David Patterson and Borivoje Nikolic
</td>

<td >UC Berkeley
</td>
</tr>
<tr style="height: 48px;" >

<td >11:00 AM
</td>

<td >Break
</td>

<td >
</td>

<td >
</td>

<td >
</td>
</tr>
<tr style="height: 48px;" >

<td >11:30 AM
</td>

<td >Graphics Solutions
</td>

<td >[Intel's High Performance Graphics solutions in thin and light mobile form factors](/hc30/1conf/1.04_Intel_Thin_Light_Gaming_HotChips_SC_Final.pdf)
</td>

<td >Srinivas Chennupaty
</td>

<td >Intel
</td>
</tr>
<tr style="height: 24px;" >

<td style="height: 24px;" >12:00 PM
</td>

<td style="height: 24px;" >
</td>

<td style="height: 24px;" >[Delivering a new level of Visual Performance in and SoC - AMD Raven Ridge APU](/hc30/1conf/1.05_AMD_APU_AMD_Raven_HotChips30_Final.pdf)
</td>

<td style="height: 24px;" >Dan Bouvier, Jim Gibney, Sonu Arora and Alex Branover
</td>

<td style="height: 24px;" >AMD
</td>
</tr>
<tr style="height: 24px;" >

<td >12:30 PM
</td>

<td >Lunch
</td>

<td >
</td>

<td >
</td>

<td >
</td>
</tr>
<tr style="height: 24px;" >

<td >1:45 PM
</td>

<td >Keynote 1: Spectre/Meltdown
</td>

<td >[The era of security: Introduction](/hc30/1conf/1.07_Hotchips_Security_Keynote.pdf)
</td>

<td >John Hennessy
</td>

<td >Stanford/Google
</td>
</tr>
<tr style="height: 24px;" >

<td >
</td>

<td >
</td>

<td >Spectre/Meltdown: the Project Zero/Reptoline journey
</td>

<td >Paul Turner
</td>

<td >Google
</td>
</tr>
<tr style="height: 24px;" >

<td >
</td>

<td >
</td>

<td >Exploiting modern microarchitectures, implications for SW
</td>

<td >Jon Masters
</td>

<td >Red Hat
</td>
</tr>
<tr style="height: 24px;" >

<td >
</td>

<td >
</td>

<td >Exploiting modern microarchitectures, implications for computer architects
</td>

<td >Mark Hill
</td>

<td >U Wisconsin-Madison
</td>
</tr>
<tr style="height: 24px;" >

<td >
</td>

<td >
</td>

<td >Panel Q & A
</td>

<td >
</td>

<td >
</td>
</tr>
<tr style="height: 24px;" >

<td >3:30 PM
</td>

<td >Break
</td>

<td >
</td>

<td >
</td>

<td >
</td>
</tr>
<tr style="height: 24px;" >

<td >4:00 PM
</td>

<td >IoT/Edge Computing
</td>

<td >[SMIV: A 16nm SoC with Efficient and Flexible DNN Acceleration for Intelligent IoT Devices](/hc30/1conf/1.10_Harvard_Whatmough_Hotchips_2018_0.7.pdf)
</td>

<td colspan="2" >Paul Whatmough (ARM), Sae Kyu Lee (IBM), Sam Xi, Udit Gupta, Lillian Pentecost, Marco Donato, Hsea-Ching Hseuh, David Brooks and Gu-Yeon Wei (Harvard University)
</td>
</tr>
<tr style="height: 24px;" >

<td >4:30 PM
</td>

<td >
</td>

<td >[Navion: An Energy-Efficient Visual-Inertial Odometry Accelerator for Micro Robotics and Beyond](/hc30/1conf/1.11_MIT_Navion_2018_hotchips_navion_slides_r1.pdf)
</td>

<td >Amr Suleiman, Zhengdong Zhang, Luca Carlone, Sertac Karaman and Vivienne Sze
</td>

<td >MIT
</td>
</tr>
<tr style="height: 24px;" >

<td >5:00 PM
</td>

<td >
</td>

<td >[NVIDIA’s Xavier System-on-Chip](/hc30/1conf/1.12_Nvidia_XavierHotchips2018Final_814.pdf)
</td>

<td >Michael Ditty
</td>

<td >NVIDIA
</td>
</tr>
<tr style="height: 24px;" >

<td >5:30 PM
</td>

<td >Security
</td>

<td >[The Hardware Security Platform Behind Azure Sphere](/hc30/1conf/1.13_Microsoft_Hardware_Security_Platform_Behind_Azure_Sphere.pdf)
</td>

<td >Doug Stiles
</td>

<td >Microsoft
</td>
</tr>
<tr style="height: 24px;" >

<td >6:00 PM
</td>

<td >
</td>

<td >[Titan: Google's Root-of-Trust Security Silicon](/hc30/1conf/1.14_Google_Titan_GoogleFinalTitanHotChips2018.pdf)
</td>

<td >Dominic Rizzo and Parthasarathy Ranganathan
</td>

<td >Google
</td>
</tr>
<tr style="height: 48px;" >

<td >6:30 PM
</td>

<td >Reception
</td>

<td >
</td>

<td >
</td>

<td >
</td>
</tr>
<tr style="height: 48px;" >

<td >7:30 PM
</td>

<td >End of Reception
</td>

<td >
</td>

<td >
</td>

<td >
</td>
</tr>
</tbody>
</table>

# Conference Day2

7:00 PMClosing Remarks
<table style="height: 2090px;" > 
<tbody >
<tr style="height: 49px;" >

<td style="height: 49px;" >**Tue 8/21**
</td>

<td style="height: 49px;" >**Session**
</td>

<td style="height: 49px;" >**Title**
</td>

<td style="height: 49px;" >**Presenter**
</td>

<td style="height: 49px;" >**Affiliation**
</td>
</tr>
<tr style="height: 48px;" >

<td style="height: 48px;" >7:45 AM
</td>

<td style="height: 48px;" >Breakfast
</td>

<td style="height: 48px;" >
</td>

<td style="height: 48px;" >
</td>

<td style="height: 48px;" >
</td>
</tr>
<tr style="height: 185px;" >

<td style="height: 185px;" >8:45 AM
</td>

<td style="height: 185px;" >Switching Fabrics and FPGA Architectures
</td>

<td style="height: 185px;" >[NVSwitch and DGX-2 – NVIDIA’s NVLink-Switching Chip and Scale-Up GPU-Compute Server](/hc30/2conf/2.01_Nvidia_NVswitch_HotChips2018_DGX2NVS_Final.pdf)
</td>

<td style="height: 185px;" >Alexander Ishii and Denis Foley
</td>

<td style="height: 185px;" >NVIDIA
</td>
</tr>
<tr style="height: 48px;" >

<td style="height: 48px;" >9:15 AM
</td>

<td style="height: 48px;" >
</td>

<td style="height: 48px;" >[Programmable Forwarding Planes at Terabit/s Speeds](/hc30/2conf/2.02_Barefoot_Barefoot_Talk_at_HotChips_2018.pdf)
</td>

<td style="height: 48px;" >Patrick Bosshart
</td>

<td style="height: 48px;" >Barefoot Networks
</td>
</tr>
<tr style="height: 146px;" >

<td style="height: 146px;" >9:45 AM
</td>

<td style="height: 146px;" >
</td>

<td style="height: 146px;" >[Xilinx Project Everest: 'HW/SW Programmable Engine'](/hc30/2conf/2.03_Xilinx_Juanjo_XilinxSWPEHotChips20180819.pdf)
</td>

<td style="height: 146px;" >Juanjo Noguera, Chris Dick, Vinod Kathail, Gaurav Singh, Kees Vissers, and Ralph Wittig
</td>

<td style="height: 146px;" >Xilinx
</td>
</tr>
<tr style="height: 48px;" >

<td style="height: 48px;" >10:15 AM
</td>

<td style="height: 48px;" >Break
</td>

<td style="height: 48px;" >
</td>

<td style="height: 48px;" >
</td>

<td style="height: 48px;" >
</td>
</tr>
<tr style="height: 73px;" >

<td style="height: 73px;" >10:45 AM
</td>

<td style="height: 73px;" >New Technologies
</td>

<td style="height: 73px;" >[Architecture for Carbon Nanotube Based Memory (NRAM)](/hc30/2conf/2.04_Nantero_20180818_hotchips_gervasi_nram_presentation.pdf)
</td>

<td style="height: 73px;" >Bill Gervasi
</td>

<td style="height: 73px;" >Nantero
</td>
</tr>
<tr style="height: 97px;" >

<td style="height: 97px;" >11:15 AM
</td>

<td style="height: 97px;" >
</td>

<td style="height: 97px;" >[Analog Computation in Flash Memory for Datacenter-scale AI Inference in a Small Chip](/hc30/2conf/2.05_Mythic_Mythic_Hot_Chips_2018_V5.pdf)
</td>

<td style="height: 97px;" >David Fick and Michael Henry
</td>

<td style="height: 97px;" >Mythic
</td>
</tr>
<tr style="height: 48px;" >

<td style="height: 48px;" >11:45 AM
</td>

<td style="height: 48px;" >Keynote 2
</td>

<td style="height: 48px;" >[Adaptable Intelligence: the Next Computing Era](/hc30/2conf/2.06_Victor_Hot_Chips_8_21_2018_Keynote_FINAL.pdf)
</td>

<td style="height: 48px;" >Victor Peng
</td>

<td style="height: 48px;" >CEO, Xilinx
</td>
</tr>
<tr style="height: 48px;" >

<td style="height: 48px;" >12:45 PM
</td>

<td style="height: 48px;" >Lunch
</td>

<td style="height: 48px;" >
</td>

<td style="height: 48px;" >
</td>

<td style="height: 48px;" >
</td>
</tr>
<tr style="height: 48px;" >

<td style="height: 48px;" >2:00 PM
</td>

<td style="height: 48px;" >Machine Learning I
</td>

<td style="height: 48px;" >[ARM's First Generation ML Processor](/hc30/2conf/2.07_ARM_ML_Processor_HC30_ARM_2018_08_17.pdf)
</td>

<td style="height: 48px;" >Ian Bratt and John Brothers
</td>

<td style="height: 48px;" >ARM
</td>
</tr>
<tr style="height: 48px;" >

<td style="height: 48px;" >2:30 PM
</td>

<td style="height: 48px;" >
</td>

<td style="height: 48px;" >[The NVIDIA Deep Learning Accelerator](/hc30/2conf/2.08_NVidia_DLA_Nvidia_DLA_HotChips_10Aug18.pdf)
</td>

<td style="height: 48px;" >Frans Sijstermans
</td>

<td style="height: 48px;" >NVIDIA
</td>
</tr>
<tr style="height: 121px;" >

<td style="height: 121px;" >3:00 PM
</td>

<td style="height: 121px;" >
</td>

<td style="height: 121px;" >[Tachyum Cloud Chip for Hyperscale workloads, deep ML, general, symbolic and bio AI](/hc30/2conf/2.09_Tachyum_Tachyum_Hotchips_2018.pdf)
</td>

<td style="height: 121px;" >Radoslav Danilak, Rodney Mullendore, Igor Shevlyakov and Kenneth Wagner
</td>

<td style="height: 121px;" >Tachyum
</td>
</tr>
<tr style="height: 551px;" >

<td style="height: 551px;" >3:30 PM
</td>

<td style="height: 551px;" >Machine Learning II
</td>

<td style="height: 551px;" >[The Evolution of Deep Learning Accelerators Upon the Evolution of Deep Learning Algorithms](/hc30/2conf/2.10_DeePhi_HC30_Deephi_SongYao_v6_20180817.pdf)
</td>

<td style="height: 551px;" >Song Yao (DeePhi Tech),
Shuang Liang (Tsinghua University), Junbin Wang, Zhongmin Chen,
Shaoxia Fang, Lingzhi Sui, Qian Yu, Dongliang Xie, Xiaoming Sun,
Song Han (MIT), Yi Shan (DeePhi Tech), and Yu Wang (Tsinghua University)
</td>

<td style="height: 551px;" >
</td>
</tr>
<tr style="height: 97px;" >

<td style="height: 97px;" >4:00 PM
</td>

<td style="height: 97px;" >
</td>

<td style="height: 97px;" >[Xilinx Tensor Processor: An Inference Engine, Network Compiler + Runtime for Xilinx FPGAs](/hc30/2conf/2.11_Xilinx_HC30_Xilinx_Rahul_Nimaiyar_08212018_v2.pdf)
</td>

<td style="height: 97px;" >Rahul Nimaiyar
</td>

<td style="height: 97px;" >Xilinx
</td>
</tr>
<tr style="height: 48px;" >

<td style="height: 48px;" >4:30 PM
</td>

<td style="height: 48px;" >Break
</td>

<td style="height: 48px;" >
</td>

<td style="height: 48px;" >
</td>

<td style="height: 48px;" >
</td>
</tr>
<tr style="height: 48px;" >

<td style="height: 48px;" >5:00 PM
</td>

<td style="height: 48px;" >Server Processors
</td>

<td style="height: 48px;" >[The IBM POWER9 Scale Up Processor](/hc30/2conf/2.12_IBM_POWER9_HC30.POWER9Cv7.pdf)
</td>

<td style="height: 48px;" >Jeffrey Stuecheli
</td>

<td style="height: 48px;" >IBM
</td>
</tr>
<tr style="height: 73px;" >

<td style="height: 73px;" >5:30 PM
</td>

<td style="height: 73px;" >
</td>

<td style="height: 73px;" >[Fujitsu High Performance CPU for the Post-K Computer](/hc30/2conf/2.13_Fujitsu_HC30.Fujitsu.Yoshida.rev1.2.pdf)
</td>

<td style="height: 73px;" >Toshio Yoshida
</td>

<td style="height: 73px;" >Fujitsu Limited
</td>
</tr>
<tr style="height: 97px;" >

<td style="height: 97px;" >6:00 PM
</td>

<td style="height: 97px;" >
</td>

<td style="height: 97px;" >[Vector Engine Processor of NEC’s Brand-New supercomputer SX-Aurora TSUBASA](/hc30/2conf/2.14_NEC_vector_NEC_SXAurora_TSUBASA_HotChips30_finalb.pdf)
</td>

<td style="height: 97px;" >Yohei Yamada and Shintaro Momose
</td>

<td style="height: 97px;" >NEC Corporation
</td>
</tr>
<tr style="height: 73px;" >

<td style="height: 73px;" >6:30 PM
</td>

<td style="height: 73px;" >
</td>

<td style="height: 73px;" >[Next Generation Intel Xeon(R) Scalable processor: Cascade Lake](/hc30/2conf/2.15_Intel_Cascade_Lake_HC30.Intel.Akhilesh.CLXCPU.Final.pdf)
</td>

<td style="height: 73px;" >Sailesh Kottapalli and Akhilesh Kumar
</td>

<td style="height: 73px;" >Intel
</td>
</tr>
<tr style="height: 48px;" >

<td style="height: 48px;" >7:15 PM
</td>

<td style="height: 48px;" >End of Conference
</td>

<td style="height: 48px;" >
</td>

<td style="height: 48px;" >
</td>

<td style="height: 48px;" >
</td>
</tr>
</tbody>
</table>

# Posters


<table cellpadding="0" cellspacing="0" border="1" dir="ltr" > 
<tbody >
<tr >

<td >Title
</td>

<td >Authors
</td>

<td >Affiliation
</td>
</tr>
<tr >

<td >[DragonFly+: FPGA-Based Quad-Camera Visual SLAM System for Autonomous Vehicles](/hc30/3posters/HotChip30ShaoshanLiu_1.pdf)
</td>

<td >Weikang Fang, Yanjun Zhang, Bo Yu and Shaoshan Liu
</td>

<td >Beijing Institute of Technology; PerceptIn
</td>
</tr>
<tr >

<td >[Ultra Low Latency and High Performance Deep Learning Processor](/hc30/3posters/HC30.Alibaba.YangKong.v01.pdf)
</td>

<td >Yang Kong, Jun Xu, Xiuyu Sun and Xulin Yu
</td>

<td >Alibaba
</td>
</tr>
<tr >

<td >[An Energy-Efficient Unified Deep Neural Network Accelerator with Fully-Variable Weight Precision for Mobile Deep Learning Applications](/hc30/3posters/An_EnergyEfficient_Unified_Deep_Neural_Network_Accelerator.pdf)
</td>

<td >Jinmook Lee, Changhyeon Kim, Sanghoon Kang, Dongjoo Shin, Sangyeob Kim and Hoi-Jun Yoo
</td>

<td >KAIST
</td>
</tr>
<tr >

<td >[AIX: FPGA geared-up Neural Network Accelerator for NUGU, the 1st Commercial Korean Virtual Personal Assistant (VPA)](/hc30/3posters/HC30.SKTelecom.MinwookAhn.v01.pdf)
</td>

<td >Minwook Ahn, Seok Joong Hwang, Wonsub Kim, Seungrok Jung, Jeong-Ho Han, Sangjun Yang, Yeonbok Lee, Jazzson Park, Mookyoung Chung, Woohyung Lim and Youngjoon Kim
</td>

<td >SK Telecom
</td>
</tr>
<tr >

<td >[DnnWeaver v2.0: From Tensors to FPGAs](/hc30/3posters/HC30.Bigstream.HardikSharma.v02.pdf)
</td>

<td >Hardik Sharma, Jongse Park, Balavinayagam Samynathan, Behnam Robatmili, Shahrzad Mirkhani and Hadi Esmaeilzadeh
</td>

<td >UC San Diego; Georgia Institute of Technology; Bigstream, Inc
</td>
</tr>
<tr >

<td >[Integrated Power Management for High Performance Computing](/hc30/3posters/Ferric_IVR_HotChips_2018_poster.pdf)
</td>

<td >Noah Sturcken
</td>

<td >Ferric, Inc.
</td>
</tr>
<tr >

<td >[Laconic: A Deep Learning Inference Hardware Accelerator](/hc30/3posters/HC30.UniversityOfToronto.SayehSharify.v01.pdf)
</td>

<td >Sayeh Sharify, Mostafa Mahmoud, Alberto Delmas Lascorz, Milos Nikolic and Andreas Moshovos
</td>

<td >University of Toronto
</td>
</tr>
<tr >

<td >[Bit-Tactical: A SW/HW Approach to Exploiting Value and Bit Sparsity in Neural Networks](/hc30/3posters/HC30.UniversityOfToronto.AlbertoDelmas.v01.pdf)
</td>

<td >Alberto Delmas Lascorz, Patrick Judd, Dylan Malone Stuart, Zissis Poulos, Mostafa Mahmoud, Sayeh Sharify, Milos Nikolic and Andreas Moshovos
</td>

<td >University of Toronto
</td>
</tr>
<tr >

<td >[High-Level Synthesis of Multithreaded Accelerators for Irregular Applications](/hc30/3posters/HC30.PNNL.Minutoli.v01.pdf)
</td>

<td >Stefano Devecchi, Nicola Saporetti, Marco Minutoli, Marco Lattuada, Pietro Fezzardi, Vito Giovanni Castellana, Fabrizio Ferrandi and Antonino Tumeo
</td>

<td >Qualcomm; Politecnico di Milano; Pacific Northwest National Laboratory (PNNL)
</td>
</tr>
</tbody>
</table>
